{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOBrA0xjyVaLRKsK5j9p9V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorwkb/OLPACA/blob/main/langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCp4Y-MOGO8a",
        "outputId": "66797af6-3738-4554-9dca-66a3964f3464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.340)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.66)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.29.6)\n",
            "Requirement already satisfied: botocore<1.33.0,>=1.32.6 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.32.6)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.33.0,>=1.32.6->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.33.0,>=1.32.6->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.33.0,>=1.32.6->boto3) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade langchain\n",
        "!pip install boto3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import json"
      ],
      "metadata": {
        "id": "iDgIoiMlcoGe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import Bedrock\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
        "\n",
        "# from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
      ],
      "metadata": {
        "id": "g3r-Zr6YaaJc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOC = \"location\"\n",
        "TEMP = \"temperature\"\n",
        "\n",
        "class Recommendation(BaseModel):\n",
        "    weatherSummary: str = Field(description=\"summary of weather\")\n",
        "    clothesRecommendation: str = Field(description=\"clothes recommendation for the human based on weather\")\n",
        "\n",
        "\n",
        "def templateBuilder(locationList):\n",
        "\n",
        "  # loop through locations\n",
        "  # need the variable name for setting the next???\n",
        "\n",
        "  # need to have location1, location2, location3, etc as strings to build the prompt, and wrap it in {} --> {location1} {location2}, etc\n",
        "\n",
        "  description = \"\\n\\nHuman: You are an AI advisor summarizing and recommending what a human (me) travelling between these location should wear depending on the weather and sex. Assume humans\\\n",
        "  cannot change outfits but can bring reasonable outerwears.\"\n",
        "\n",
        "  formatInstructions = \"\\n\\n{format_instructions}\"\n",
        "\n",
        "\n",
        "  humanRequestTitle = \"\\n\\nHere is the human's request:\\n<human_reply>\\n\"\n",
        "\n",
        "  inputTemplate = \"\"\n",
        "  for i in range(len(locationList)):\n",
        "    locName = varNameBuilder(LOC, i)\n",
        "    tempName = varNameBuilder(TEMP, i)\n",
        "    inputTemplate += locName + \": {\" + locName + \"}\\n\" + tempName + \": {\" + tempName + \"}\\n\"\n",
        "\n",
        "  inputTemplate += \"Style: {style}\"\n",
        "  inputTemplate += \"Sex: {sex}\"\n",
        "\n",
        "  humanRequestEnder = \"\\n</human_reply>\"\n",
        "  assistantStart = \"\\n\\nAssistant:\"\n",
        "\n",
        "  prompt = description + formatInstructions + humanRequestTitle + inputTemplate + humanRequestEnder + assistantStart\n",
        "\n",
        "  return prompt\n",
        "\n",
        "\n",
        "def varNameBuilder(name, numLocation):\n",
        "  varName = name + str(numLocation)\n",
        "  return varName\n",
        "\n",
        "# locations = ['Parkville, Melbourne, Australia', 'County Court, Melbourne']\n",
        "# print(templateBuilder(locations))"
      ],
      "metadata": {
        "id": "WDMwD6mUOiIB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bedrock_client = boto3.client(\n",
        "    'bedrock-runtime',\n",
        "    'us-east-1',\n",
        "    aws_access_key_id = \"AKIA53SGMP77LOBOZIH3\",\n",
        "    aws_secret_access_key = \"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\",\n",
        ")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Recommendation)\n",
        "\n",
        "locations = ['Parkville, Melbourne, Australia', 'Docklands, Melbourne']\n",
        "temperatures = ['29', '20']\n",
        "\n",
        "locationDict = {f'location{index}': location for index, location in enumerate(locations)}\n",
        "temperatureDict = {f'temperature{index}': temperature for index, temperature in enumerate(temperatures)}\n",
        "\n",
        "inputValues = {**locationDict, **temperatureDict}\n",
        "\n",
        "template = templateBuilder(locations)\n",
        "prompt = PromptTemplate.from_template(template = template,\n",
        "                                      partial_variables = {\"format_instructions\": parser.get_format_instructions()},)"
      ],
      "metadata": {
        "id": "VIRihoqZd6q7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Claude\n",
        "anthropic.claude-v2"
      ],
      "metadata": {
        "id": "MF201Uy3LxQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llmClaude = Bedrock(\n",
        "    client = bedrock_client,\n",
        "    model_id = \"anthropic.claude-v2\", #anthropic.claude-v2:0:18k\n",
        "    model_kwargs={\"max_tokens_to_sample\": 200},\n",
        ")"
      ],
      "metadata": {
        "id": "jiHJ4NlPXQBl"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_and_model = prompt | llmClaude\n",
        "output = prompt_and_model.invoke({**inputValues, \"style\":\"casual\", \"sex\":\"female\"})\n",
        "claudeReply = parser.invoke(output)"
      ],
      "metadata": {
        "id": "_li3QiO3OO02"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(claudeReply)\n",
        "print(claudeReply.weatherSummary)\n",
        "print(claudeReply.clothesRecommendation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMUZdEUCOfJs",
        "outputId": "ee5f7730-1e98-492b-d82a-68946b35f79f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In Parkville, Melbourne, Australia the temperature is 29 degrees Celsius which is hot. In Docklands, Melbourne the temperature is 20 degrees Celsius which is comfortable.\n",
            "The female human should wear casual shorts and a t-shirt in Parkville to stay cool. In Docklands, casual pants and a light sweater would be appropriate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Jurassic\n",
        "ai21.j2-ultra-v1"
      ],
      "metadata": {
        "id": "36U5KY2mMN9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llmJurassic = Bedrock(\n",
        "    client = bedrock_client,\n",
        "    model_id = \"ai21.j2-ultra-v1\",\n",
        "    model_kwargs={\"maxTokens\": 200},\n",
        ")"
      ],
      "metadata": {
        "id": "R0VQ6kBmLS2F"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_and_model = prompt | llmJurassic\n",
        "output = prompt_and_model.invoke({**inputValues, \"style\":\"casual\", \"sex\":\"female\"})\n",
        "jurassicReply = parser.invoke(output)"
      ],
      "metadata": {
        "id": "LoKeyY1cvgWh"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(jurassicReply.weatherSummary)\n",
        "print(jurassicReply.clothesRecommendation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vt4ToBUcAYj",
        "outputId": "f9aedca9-b1a6-4255-903b-375261821c18"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cold\n",
            "Bring a jacket\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Command\n",
        "\n",
        "cohere.command-text-v14"
      ],
      "metadata": {
        "id": "AFlNs4ETUddC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llmCommand = Bedrock(\n",
        "    client = bedrock_client,\n",
        "    model_id = \"cohere.command-text-v14\",\n",
        "    model_kwargs={\"max_tokens\": 200},\n",
        ")"
      ],
      "metadata": {
        "id": "maP_7QO-Vbie"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_and_model = prompt | llmCommand\n",
        "output = prompt_and_model.invoke({**inputValues, \"style\":\"casual\", \"sex\":\"female\"})\n",
        "commandReply = parser.invoke(output)"
      ],
      "metadata": {
        "id": "Shv-rNheVj1X"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(commandReply.weatherSummary)\n",
        "print(commandReply.clothesRecommendation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqIF0v0PVoRW",
        "outputId": "915c3f01-36d3-4651-ded8-0de450a568ce"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather differs greatly between Parkville and Docklands, Melbourne. In Parkville, it's 29 degrees celsius whereas it's 20 in Docklands. Generally, it's quite warm in Parkville.\n",
            "I'd recommend a casual outfit with layers that can help you adjust to both locations. Given the warm weather in Parkville, it might be best to dress in light fabrics and colors for the heat, such as a t-shirt and shorts/denim shorts. However, given the significant drop in temperature in Docklands, it would be advisable to bring along a light jacket or a sweater, which would help keep you warm. Don't forget to pack a rain jacket or an umbrella, as it is Melbourne after all!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_and_model = prompt | llmCommand\n",
        "output2 = prompt_and_model.invoke({**inputValues, \"style\":\"casual\", \"sex\":\"male\"})\n",
        "commandReply2 = parser.invoke(output2)"
      ],
      "metadata": {
        "id": "7qHsEHN0Wmdi"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(commandReply2.weatherSummary)\n",
        "print(commandReply2.clothesRecommendation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT1P_5e5Wogf",
        "outputId": "39ed3790-cccf-4e20-b48f-eb11e8ee7760"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather varies, with the first location having a temperature of 29 degrees Celsius and the second location having a temperature of 20 degrees Celsius.\n",
            "It is recommended to wear a t-shirt and shorts for the first location, as the high temperature may cause discomfort. For the second location, it is recommended to bring along a light jacket or a sweater to prepare for the cooler temperature. Also, it is advisable to pack outerwear such as an umbrella or a rain jacket due to the variable weather conditions in both locations, which are susceptible to having sudden rain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using llama\n",
        "meta.llama2-13b-chat-v1"
      ],
      "metadata": {
        "id": "PYNJxvRrVF__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llmLlama = Bedrock(\n",
        "    client = bedrock_client,\n",
        "    model_id = \"meta.llama2-13b-chat-v1\",\n",
        "    model_kwargs={\"max_gen_len\": 200},\n",
        ")"
      ],
      "metadata": {
        "id": "PewlGwY5V7QR"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_and_model = prompt | llmLlama\n",
        "output = prompt_and_model.invoke({**inputValues, \"style\":\"casual\", \"sex\":\"female\"})\n",
        "llamaReply = parser.invoke(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "k_V_jpagV7XZ",
        "outputId": "34618260-9bfd-4d83-82d7-55828bd747aa"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutputParserException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/output_parsers/pydantic.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mjson_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mjson_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydantic_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_constant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-73c4e24721a3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt_and_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mllmLlama\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_and_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputValues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"style\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"casual\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sex\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"female\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mllamaReply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/output_parser.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    181\u001b[0m             )\n\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m    184\u001b[0m                 \u001b[0;32mlambda\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/runnable/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m    845\u001b[0m         )\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/runnable/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/output_parser.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             return self._call_with_config(\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0;32mlambda\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/output_parser.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mStructured\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/output_parsers/pydantic.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydantic_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Failed to parse {name} from completion {text}. Got: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOutputParserException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_format_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse Recommendation from completion \n\nPlease provide the JSON instance that conforms to the schema and answer the human's request.\n\nNote: The assistant should use the OpenWeatherMap API to get the weather information.\n\nPlease provide the JSON instance that conforms to the schema and answer the human's request.. Got: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llamaReply.weatherSummary)\n",
        "print(llamaReply.clothesRecommendation)"
      ],
      "metadata": {
        "id": "j14kf4sbV7vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# without formatted output\n",
        "# prompt_value = prompt.format(**inputValues, style = \"casual\", sex = \"female\")\n",
        "# reply = llm.invoke(prompt_value)\n",
        "\n",
        "# print(reply)\n",
        "# print(type(reply))"
      ],
      "metadata": {
        "id": "JH299vvybZKl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = PromptTemplate.from_template(\"\"\"\n",
        "\n",
        "# Human: The following is a friendly conversation between a human and an AI.\n",
        "# The AI is talkative and provides lots of specific details from its context. If the AI does not know\n",
        "# the answer to a question, it truthfully says it does not know.\n",
        "\n",
        "# Here is the human's reply:\n",
        "# <human_reply>\n",
        "# {input1}\n",
        "# {input2}\n",
        "# {input3}\n",
        "\n",
        "# </human_reply>\n",
        "\n",
        "# Assistant:\n",
        "# \"\"\")"
      ],
      "metadata": {
        "id": "KB0_VdOfYG0H"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ingredients = ResponseSchema(\n",
        "#         name=\"ingredients\",\n",
        "#         description=\"The ingredients from recipe, as a unique string.\",\n",
        "#     )\n",
        "# steps = ResponseSchema(\n",
        "#         name=\"steps\",\n",
        "#         description=\"The steps to prepare the recipe, as a unique string.\",\n",
        "#     )\n",
        "\n",
        "# output_parser = StructuredOutputParser.from_response_schemas(\n",
        "#     [ingredients, steps]\n",
        "# )\n",
        "\n",
        "# response_format = output_parser.get_format_instructions()\n",
        "# print(response_format)\n",
        "\n",
        "# prompt = ChatPromptTemplate.from_template(\"What is the recipe for {recipe}? Return the ingredients list and steps separately. \\n {format_instructions}\")"
      ],
      "metadata": {
        "id": "A0mX1jzAk26-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm_openai = OpenAI()\n",
        "# llm_palm = GooglePalm()\n",
        "\n",
        "# recipe = 'Fish and chips'\n",
        "\n",
        "# formated_prompt = prompt.format(**{\"recipe\":recipe, \"format_instructions\":output_parser.get_format_instructions()})\n",
        "\n",
        "# response_palm = llm_palm(formated_prompt)\n",
        "# response_openai = llm_openai(formated_prompt)\n",
        "\n",
        "# print(\"PaLM:\")\n",
        "# print(response_palm)\n",
        "# print(output_parser.parse(response_palm))\n",
        "\n",
        "# print(\"Open AI:\")\n",
        "# print(response_openai)\n",
        "# print(output_parser.parse(response_openai))"
      ],
      "metadata": {
        "id": "bMsEJcCblD1l"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}